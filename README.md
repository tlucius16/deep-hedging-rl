# Deep Hedging with Reinforcement Learning

This repository explores **reinforcement learningâ€“based hedging strategies** for SPX & SPY options.  
We use Bloomberg/WRDS data (kept local), simulators, and RL agents to test risk management performance.  

---

## ğŸ“‚ Project Structure

deep-hedging-rl/
â”‚
â”œâ”€â”€ data/ # (DO NOT push raw Bloomberg data, keep locally)
â”‚ â”œâ”€â”€ raw/ # local-only (ignored in .gitignore)
â”‚ â””â”€â”€ processed/ # small sample/cleaned data for demos
â”‚
â”œâ”€â”€ notebooks/ # Jupyter/Colab notebooks
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_simulator_dev.ipynb
â”‚ â”œâ”€â”€ 03_rl_training.ipynb
â”‚ â””â”€â”€ 04_results_analysis.ipynb
â”‚
â”œâ”€â”€ src/ # main Python modules
â”‚ â”œâ”€â”€ data_pipeline/ # wrds/bloomberg loaders, cleaning functions
â”‚ â”œâ”€â”€ simulator/ # hedging environment (Gym API)
â”‚ â”œâ”€â”€ rl_agent/ # RL models, training loop
â”‚ â”œâ”€â”€ evaluation/ # metrics, risk attribution, plots
â”‚ â””â”€â”€ utils/ # helpers, config, logging
â”‚
â”œâ”€â”€ experiments/ # configs & logs for each run
â”‚ â”œâ”€â”€ configs/ # YAML/JSON config files
â”‚ â””â”€â”€ logs/ # training logs, wandb/mlflow outputs
â”‚
â”œâ”€â”€ reports/ # paper drafts, figures, slides
â”‚
â”œâ”€â”€ requirements.txt # pinned dependencies
â”œâ”€â”€ environment.yml # optional, for conda setup
â”œâ”€â”€ .gitignore # makes sure raw data is excluded
â”œâ”€â”€ README.md # project overview, setup, usage
â””â”€â”€ LICENSE # license if publishing



---

## âš™ï¸ Setup

### Option 1: Conda (recommended)
```bash
conda env create -f environment.yml
conda activate deep-hedging-rl


pip install -r requirements.txt
