{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a786df96-a53c-4fb9-bf72-5629cb745318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load pipeline output\n",
    "df = pd.read_csv(\"data/processed/market_daily.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "# Drop any rows with missing data\n",
    "df_clean = df.dropna(how=\"any\")\n",
    "\n",
    "# Save clean versions\n",
    "df_clean.to_csv(\"data/processed/market_daily_clean.csv\")\n",
    "df_clean.to_parquet(\"data/processed/market_daily_clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d2914c6-a61c-4227-98fe-ce7e44e649df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned market_daily.csv\n",
      "✅ Cleaned market_daily.parquet\n",
      "✅ Cleaned market_extended_spx.csv\n",
      "✅ Cleaned market_extended_spx.parquet\n",
      "✅ Cleaned market_extended_spy.csv\n",
      "✅ Cleaned market_extended_spy.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22308\\2187554634.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned options_snapshot_spx.csv\n",
      "✅ Cleaned options_snapshot_spx.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22308\\2187554634.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned options_snapshot_spy.csv\n",
      "✅ Cleaned options_snapshot_spy.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22308\\2187554634.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned vol_surface_spx.csv\n",
      "✅ Cleaned vol_surface_spx.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22308\\2187554634.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned vol_surface_spy.csv\n",
      "✅ Cleaned vol_surface_spy.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "processed_path = \"data/processed\"\n",
    "cleaned_path = os.path.join(processed_path, \"cleaned\")\n",
    "os.makedirs(cleaned_path, exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(processed_path):\n",
    "    if (\"clean\" in fname.lower()) or fname.startswith(\".\") or fname.endswith(\".txt\"):\n",
    "        continue  # skip already-cleaned, hidden, or placeholder files\n",
    "\n",
    "    fpath = os.path.join(processed_path, fname)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n",
    "    elif ext == \".parquet\":\n",
    "        df = pd.read_parquet(fpath)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Drop NaNs\n",
    "    df_clean = df.dropna(how=\"any\")\n",
    "\n",
    "    # Save as both CSV + Parquet\n",
    "    df_clean.to_csv(os.path.join(cleaned_path, f\"{base}_clean.csv\"))\n",
    "    df_clean.to_parquet(os.path.join(cleaned_path, f\"{base}_clean.parquet\"))\n",
    "\n",
    "    print(f\"✅ Cleaned {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "137de5db-549c-4a89-b20c-67c27414fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded market_daily: 1996-01-04 00:00:00 → 2025-08-29 00:00:00, 10831 rows\n",
      "Loaded market_extended_spx: 1996-01-04 00:00:00 → 2023-08-31 00:00:00, 6963 rows\n",
      "Loaded market_extended_spy: 2005-01-10 00:00:00 → 2023-08-31 00:00:00, 4693 rows\n",
      "Loaded options_snapshot_spx: 1996-01-04 00:00:00 → 2023-08-31 00:00:00, 6963 rows\n",
      "Loaded options_snapshot_spy: 2005-01-10 00:00:00 → 2023-08-31 00:00:00, 4692 rows\n",
      "Loaded vol_surface_spx: 1996-01-04 00:00:00 → 2023-08-31 00:00:00, 6963 rows\n",
      "Loaded vol_surface_spy: 2005-01-10 00:00:00 → 2023-08-31 00:00:00, 4693 rows\n",
      "\n",
      "✅ Final aligned dataset saved in: data\\processed\\aligned\n",
      "Shape: (4692, 78)\n",
      "Date range: 2005-01-10 00:00:00 to 2023-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "cleaned_path = \"data/processed/cleaned\"\n",
    "aligned_path = os.path.join(\"data\", \"processed\", \"aligned\")\n",
    "os.makedirs(aligned_path, exist_ok=True)\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for fname in os.listdir(cleaned_path):\n",
    "    if fname.endswith(\".csv\") and \"clean\" in fname:\n",
    "        key = fname.replace(\"_clean.csv\", \"\")\n",
    "        fpath = os.path.join(cleaned_path, fname)\n",
    "\n",
    "        # Load file\n",
    "        df = pd.read_csv(fpath)\n",
    "\n",
    "        # If a \"date\" column exists, parse it\n",
    "        if \"date\" in df.columns:\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "            df = df.set_index(\"date\")\n",
    "        else:\n",
    "            # Otherwise assume first column is the index\n",
    "            df = pd.read_csv(fpath, parse_dates=True, index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "\n",
    "        # Drop NaT (invalid dates) from index\n",
    "        df = df[~df.index.isna()]\n",
    "\n",
    "        # Drop duplicate dates\n",
    "        df = df[~df.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        dfs[key] = df\n",
    "        print(f\"Loaded {key}: {df.index.min()} → {df.index.max()}, {len(df)} rows\")\n",
    "\n",
    "# Align all datasets on their common overlapping dates\n",
    "final_df = pd.concat(dfs.values(), axis=1, join=\"inner\")\n",
    "\n",
    "# Prefix columns with dataset names\n",
    "final_df.columns = [f\"{k}__{col}\" for k, df in dfs.items() for col in df.columns]\n",
    "\n",
    "# Save final aligned dataset\n",
    "final_df.to_csv(os.path.join(aligned_path, \"final_aligned.csv\"))\n",
    "final_df.to_parquet(os.path.join(aligned_path, \"final_aligned.parquet\"))\n",
    "\n",
    "print(\"\\n✅ Final aligned dataset saved in:\", aligned_path)\n",
    "print(\"Shape:\", final_df.shape)\n",
    "print(\"Date range:\", final_df.index.min(), \"to\", final_df.index.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep-hedging-rl)",
   "language": "python",
   "name": "deep-hedging-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
